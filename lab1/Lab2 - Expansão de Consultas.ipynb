{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix and Vocabulary Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código feito pelos monitores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import math\n",
    "__author__ = \"Thierry Barros\"\n",
    "\n",
    "indice_invertido = {}\n",
    "dados_TF = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"../data/estadao_noticias_eleicao.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = news.titulo + \" \" + news.subTitulo + \" \" + news.conteudo\n",
    "content = content.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occurrence_matrix(corpus):\n",
    "    vocab = set(corpus)\n",
    "    vocab = list(vocab)\n",
    "    n = len(vocab)\n",
    "   \n",
    "    vocab_to_index = {word:i for i, word in enumerate(vocab)}\n",
    "    \n",
    "    bi_grams = list(bigrams(corpus))\n",
    "\n",
    "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
    "\n",
    "    I=list()\n",
    "    J=list()\n",
    "    V=list()\n",
    "    \n",
    "    for bigram in bigram_freq:\n",
    "        current = bigram[0][1]\n",
    "        previous = bigram[0][0]\n",
    "        count = bigram[1]\n",
    "\n",
    "        I.append(vocab_to_index[previous])\n",
    "        J.append(vocab_to_index[current])\n",
    "        V.append(count)\n",
    "        \n",
    "    co_occurrence_matrix = sparse.coo_matrix((V,(I,J)), shape=(n,n))\n",
    "\n",
    "    return co_occurrence_matrix, vocab_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens_lists = content.apply(lambda text: tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_ = stopwords.words('portuguese')\n",
    "filtered_tokens = tokens_lists.apply(lambda tokens: [token for token in tokens if token not in stopword_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming list of lists into one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token for tokens_list in filtered_tokens for token in tokens_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, vocab = co_occurrence_matrix(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consult Bigram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consultable_matrix = matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consult_frequency(w1, w2):\n",
    "    return(consultable_matrix[vocab[w1],vocab[w2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código do lab 1 para pesquisa OR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preencher( tupla ):\n",
    "    palavra, id_texto = tupla\n",
    "    if palavra.lower() not in dados_TF[id_texto]:\n",
    "        dados_TF[id_texto][palavra.lower()] = 0\n",
    "    dados_TF[id_texto][palavra.lower()] += 1\n",
    "    try:\n",
    "        indice_invertido [ palavra.lower() ].add(id_texto)\n",
    "    except KeyError:\n",
    "        indice_invertido[ palavra.lower() ] = set([ id_texto ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extrair( texto , id_texto ):\n",
    "    for i in xrange( len(texto) ):\n",
    "        dados_TF[id_texto[i]]= {}\n",
    "        for palavra in nltk.word_tokenize( str(texto[i]).decode('utf-8') ):\n",
    "            preencher((palavra,id_texto[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_csv = pd.read_csv(\"../data/estadao_noticias_eleicao.csv\")\n",
    "    file_csv = file_csv.replace(np.nan, '', regex=True)\n",
    "    texto = file_csv.titulo + \" \" + file_csv.conteudo + \" \" + file_csv.subTitulo\n",
    "    extrair(texto,file_csv.idNoticia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código do Lab2 - Expansão de Consultas.\n",
    "\n",
    "##Escreva uma função que receba um certo termo de consulta e a matriz construída no passo 1 acima e retorne as top-3 palavras em ordem decrescente de frequencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função pega os tokens(todas as palavras do dicionário), faz um set para tirar as repetições, depois tranforma e lista denovo. Então eu crio uma lista(dic), contendo tuplas de (palavra, frequência da palavra com o termo). Após a criação dessa lista, eu ordeno ela pela frequência, e pego as três palavras com maior frequência e retorno elas. \n",
    "OBS: Crio essa lista de nome, frequencia, ultilizando a função auxiliar consult_frequency(word, i), criada pelos monitores da turma, então eu não preciso receber na função a matrix de co-ocorrência, porque essa função já usa a matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top3_similarity(word):\n",
    "    words = set(tokens)\n",
    "    words = list(words)\n",
    "    dic = []\n",
    "    for i in words:\n",
    "        try:\n",
    "            dic.append((i, consult_frequency(word, i)))\n",
    "        except KeyError:\n",
    "            return [\"Not Found: palavra '\"+word+\"' não encontrada\"]\n",
    "    dic.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    similar_words = []\n",
    "    for tupla in dic[:3]:\n",
    "       similar_words.append(tupla[0])\n",
    "    return similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Expanda a consulta original com os termos retornados no passo 2 acima.\n",
    "\n",
    "Essa função recebe o termo a ser procurado e retorna a lista expandida com os top3 palavras mais similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_consult(word):\n",
    "    words = []\n",
    "    words.append(word)\n",
    "    words += top3_similarity(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Faça uma busca disjuntiva (OR) considerando a nova consulta.\n",
    "\n",
    "**Função de busca OR Binário.**\n",
    "Função de busca que retorna os documentos que possuem pelo menos uma das palavras da consulta. Função de labs anteriores é uma função de busca binária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procurarOR(lista):\n",
    "    indices = indice_invertido[lista[0].lower()]\n",
    "    for palavra in lista:\n",
    "        indices = set(reduce( lambda x,y : list( x | y ), [ indice_invertido[palavra.lower()] , indices] ))\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Quais os termos retornados para a expansão de cada consulta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term1 = \"poucos\"\n",
    "term2 = \"recursos\"\n",
    "term3 = \"corinthians\"\n",
    "\n",
    "terms1 = top3_similarity(term1)\n",
    "\n",
    "terms2 = top3_similarity(term2)\n",
    "\n",
    "terms3 = top3_similarity(term3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Consulta **poucos**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Termos encontrados na expansão da pesquisa de \"+term1+\":\")\n",
    "for i, word in enumerate(terms1):\n",
    "    print i+1,word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Você acha que esses termos são de fato relacionados com a consulta original? Justifique.**\n",
    "\n",
    "Sim, pois são termos que em conjunto fazem sentido. Exemplo: poucos dias, poucos meses, poucos metros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Consulta **recursos**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Termos encontrados na expansão da pesquisa de \"+term2+\":\")\n",
    "for i, word in enumerate(terms2):\n",
    "    print i+1,word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Você acha que esses termos são de fato relacionados com a consulta original? Justifique.**\n",
    "\n",
    "Sim, mas acho que só duas das palavras fazem sentido, que são públicos e petrobrás. Recursos fundo não parece fazer muito sentido em conjunto, mas pode ser porque a frase não está completa, poderia ter outras palavras após essas que na frase fariam mais sentido. Já, recursos públicos e recursos petrobrás parece fazer sentido, deve possivelmente está relacionado ao interesse dos usuários em saber como estão sendo gastos os recursos do país."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Consulta **corinthians**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Termos encontrados na expansão da pesquisa de \"+term3+\":\")\n",
    "for i, word in enumerate(terms3):\n",
    "    print i+1,word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Você acha que esses termos são de fato relacionados com a consulta original? Justifique.**\n",
    "\n",
    "Sim, pois andrés é o presidente do timão. 2010 deve ter sido a pesquisa em alta no ano da captação desses dados, procurando saber como o corinthians foi ou que jogos ele teria no ano de 2010. Paulo pode ser uma palavra ambígua, tanto pode representa o estado de São paulo, ou algum jogador chamado paulo que fez sucesso no corinthians na época, confesso que não lembro de nenhum jogador com esse nome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare os documentos retornados para a consulta original com a consulta expandida. Quais resultados você acha que melhor capturam a necessidade de informação do usuário? Por que?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(procurarOR([term1]))\n",
    "print(procurarOR(terms1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#A expansão de consultas é mais adequada para melhorar o recall ou o precision? Por que?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
