{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix and Vocabulary Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código feito pelos monitores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import math\n",
    "__author__ = \"Thierry Barros\"\n",
    "\n",
    "indice_invertido = {}\n",
    "dados_TF = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"../data/estadao_noticias_eleicao.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = news.titulo + \" \" + news.subTitulo + \" \" + news.conteudo\n",
    "content = content.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occurrence_matrix(corpus):\n",
    "    vocab = set(corpus)\n",
    "    vocab = list(vocab)\n",
    "    n = len(vocab)\n",
    "   \n",
    "    vocab_to_index = {word:i for i, word in enumerate(vocab)}\n",
    "    \n",
    "    bi_grams = list(bigrams(corpus))\n",
    "\n",
    "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
    "\n",
    "    I=list()\n",
    "    J=list()\n",
    "    V=list()\n",
    "    \n",
    "    for bigram in bigram_freq:\n",
    "        current = bigram[0][1]\n",
    "        previous = bigram[0][0]\n",
    "        count = bigram[1]\n",
    "\n",
    "        I.append(vocab_to_index[previous])\n",
    "        J.append(vocab_to_index[current])\n",
    "        V.append(count)\n",
    "        \n",
    "    co_occurrence_matrix = sparse.coo_matrix((V,(I,J)), shape=(n,n))\n",
    "\n",
    "    return co_occurrence_matrix, vocab_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens_lists = content.apply(lambda text: tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_ = stopwords.words('portuguese')\n",
    "filtered_tokens = tokens_lists.apply(lambda tokens: [token for token in tokens if token not in stopword_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming list of lists into one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token for tokens_list in filtered_tokens for token in tokens_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, vocab = co_occurrence_matrix(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consult Bigram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "consultable_matrix = matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consult_frequency(w1, w2):\n",
    "    return(consultable_matrix[vocab[w1],vocab[w2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código do lab 1 para pesquisa OR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preencher( tupla ):\n",
    "    palavra, id_texto = tupla\n",
    "    if palavra.lower() not in dados_TF[id_texto]:\n",
    "        dados_TF[id_texto][palavra.lower()] = 0\n",
    "    dados_TF[id_texto][palavra.lower()] += 1\n",
    "    try:\n",
    "        indice_invertido [ palavra.lower() ].add(id_texto)\n",
    "    except KeyError:\n",
    "        indice_invertido[ palavra.lower() ] = set([ id_texto ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extrair( texto , id_texto ):\n",
    "    for i in xrange( len(texto) ):\n",
    "        dados_TF[id_texto[i]]= {}\n",
    "        for palavra in nltk.word_tokenize( str(texto[i]).decode('utf-8') ):\n",
    "            preencher((palavra,id_texto[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Faça uma busca disjuntiva (OR) considerando a nova consulta.\n",
    "\n",
    "**Função de busca OR Binário.**\n",
    "Função de busca que retorna os documentos que possuem pelo menos uma das palavras da consulta. Função de labs anteriores é uma função de busca binária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procurarOR(lista):\n",
    "    indices = indice_invertido[lista[0].lower()]\n",
    "    for palavra in lista:\n",
    "        indices = set(reduce( lambda x,y : list( x | y ), [ indice_invertido[palavra.lower()] , indices] ))\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Função main** que roda o programa e cria o indíce invertido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_csv = pd.read_csv(\"../data/estadao_noticias_eleicao.csv\")\n",
    "file_csv = file_csv.replace(np.nan, '', regex=True)\n",
    "texto = file_csv.titulo + \" \" + file_csv.conteudo + \" \" + file_csv.subTitulo\n",
    "extrair(texto,file_csv.idNoticia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código do Lab2 - Expansão de Consultas.\n",
    "\n",
    "#Escreva uma função que receba um certo termo de consulta e a matriz construída no passo 1 acima e retorne as top-3 palavras em ordem decrescente de frequencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função pega os tokens(todas as palavras do dicionário), faz um set para tirar as repetições, depois tranforma e lista denovo. Então eu crio uma lista(dic), contendo tuplas de (palavra, frequência da palavra com o termo). Após a criação dessa lista, eu ordeno ela pela frequência, e pego as três palavras com maior frequência e retorno elas. \n",
    "OBS: Crio essa lista de nome, frequencia, ultilizando a função auxiliar consult_frequency(word, i), criada pelos monitores da turma, então eu não preciso receber na função a matrix de co-ocorrência, porque essa função já usa a matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top3_similarity(word):\n",
    "    words = set(tokens)\n",
    "    words = list(words)\n",
    "    dic = []\n",
    "    for i in words:\n",
    "        try:\n",
    "            dic.append((i, consult_frequency(word, i)))\n",
    "        except KeyError:\n",
    "            return [\"Not Found: palavra '\"+word+\"' não encontrada\"]\n",
    "    dic.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    similar_words = []\n",
    "    for tupla in dic[:3]:\n",
    "       similar_words.append(tupla[0])\n",
    "    return similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Expanda a consulta original com os termos retornados no passo 2 acima.\n",
    "\n",
    "Essa função recebe o termo a ser procurado e retorna a lista expandida com os top3 palavras mais similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_consult(word):\n",
    "    words = []\n",
    "    words.append(word)\n",
    "    words += top3_similarity(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Escolha livremente três termos de consulta e responda o seguinte:\n",
    "\n",
    "**Os três termos escolhidos foram: Poucos, recursos, corinthians.**\n",
    "\n",
    "#Quais os termos retornados para a expansão de cada consulta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = \"dilma\"\n",
    "word2 = \"recursos\"\n",
    "word3 = \"corinthians\"\n",
    "\n",
    "ex_word1 = expand_consult(word1)\n",
    "\n",
    "ex_word2 = expand_consult(word2)\n",
    "\n",
    "ex_word3 = expand_consult(word3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Consulta **dilma**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termos encontrados na expansão da pesquisa de dilma:\n",
      "1 dilma\n",
      "2 rousseff\n",
      "3 é\n",
      "4 disse\n"
     ]
    }
   ],
   "source": [
    "print(\"Termos encontrados na expansão da pesquisa de \"+word1+\":\")\n",
    "for i, word in enumerate(ex_word1):\n",
    "    print i+1,word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Você acha que esses termos são de fato relacionados com a consulta original? Justifique.**\n",
    "\n",
    "Sim, pois são termos que em conjunto fazem sentido. Exemplo: Dilma Rousseff que é o sobre nome dela, dilma é, dilma disse(já que ela gosta de fazer várias discursos e declarações polêmicas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Consulta **recursos**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termos encontrados na expansão da pesquisa de recursos:\n",
      "1 recursos\n",
      "2 públicos\n",
      "3 fundo\n",
      "4 petrobrás\n"
     ]
    }
   ],
   "source": [
    "print(\"Termos encontrados na expansão da pesquisa de \"+word2+\":\")\n",
    "for i, word in enumerate(ex_word2):\n",
    "    print i+1,word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Você acha que esses termos são de fato relacionados com a consulta original? Justifique.**\n",
    "\n",
    "Sim, mas acho que só duas das palavras fazem sentido, que são públicos e petrobrás. Recursos fundo não parece fazer muito sentido em conjunto, mas pode ser porque a frase não está completa, poderia ter outras palavras após essas que na frase fariam mais sentido. Já, recursos públicos e recursos petrobrás parece fazer sentido, deve possivelmente está relacionado ao interesse dos usuários em saber como estão sendo gastos os recursos do país."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Consulta **corinthians**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termos encontrados na expansão da pesquisa de corinthians:\n",
      "1 corinthians\n",
      "2 andrés\n",
      "3 2010\n",
      "4 paulo\n"
     ]
    }
   ],
   "source": [
    "print(\"Termos encontrados na expansão da pesquisa de \"+word3+\":\")\n",
    "for i, word in enumerate(ex_word3):\n",
    "    print i+1,word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Você acha que esses termos são de fato relacionados com a consulta original? Justifique.**\n",
    "\n",
    "Sim, pois Andrés é o presidente do timão. 2010 deve ter sido a pesquisa em alta no ano da captação desses dados, procurando saber como o corinthians foi ou que jogos ele teria no ano de 2010. Paulo pode ser uma palavra ambígua, oque pode trazer problemas com falsos positivos caso seja uma palavra estatísticamente irrelevante, mas ela tanto pode representar o estado de São paulo, ou algum jogador chamado Paulo que fez sucesso no corinthians na época, confesso que não lembro de nenhum jogador com esse nome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare os documentos retornados para a consulta original com a consulta expandida. Quais resultados você acha que melhor capturam a necessidade de informação do usuário? Por que?**\n",
    "\n",
    "Para responder essa questão vou pegar **5 documentos** da consulta com o **termo original** e da consulta **expandida** e olhar manualmente quais documentos de quais pesquisas são **mais relevantes para a consulta original**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_csv = pd.read_csv(\"../data/estadao_noticias_eleicao.csv\")\n",
    "file_csv = file_csv.replace(np.nan, '', regex=True)\n",
    "titulo = file_csv.titulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Documentos da consulta **poucos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos retornados pela consulta original:\n",
      "\n",
      "1 Dilma anuncia últimos 14 ministros e fecha equipe\n",
      "2 Ex-governador critica Alckmin pela falta de água em SP\n",
      "3 Veja lista completa de ministros anunciados por Dilma\n",
      "4 'PT não pode se queixar', afirma futuro articulador  \n",
      "5 Planalto confirma Juca Ferreira no Ministério da Cultura\n",
      "\n",
      "Documentos retornados pela consulta expandida:\n",
      "\n",
      "1 Planalto confirma Juca Ferreira no Ministério da Cultura\n",
      "2 Pimentel divulga nomes do secretariado do governo de Minas\n",
      "3 Ala do PT pede saída de Ideli de ministério\n",
      "4 Cid Gomes anunciará novo piso para professores em janeiro\n",
      "5 Além de ministério, PRB ganha pastas estaduais de Esporte   \n"
     ]
    }
   ],
   "source": [
    "documentos = list(procurarOR([word1]))[10:15]\n",
    "documentos_extendidos = list(procurarOR(ex_word1))[10:15]\n",
    "print(\"Documentos retornados pela consulta original:\\n\")\n",
    "for i,indice in enumerate(documentos):\n",
    "    print i+1,titulo[indice]\n",
    "print(\"\\nDocumentos retornados pela consulta expandida:\\n\")\n",
    "for i,indice in enumerate(documentos_extendidos):\n",
    "    print i+1,titulo[indice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso da pesquisa por Dilma, como é um nome bem incomum a pesquisa expandida não parece ter trazido documentos mais relevantes, isso claro se baseando apenas no título de algumas notícias, oque não serve de prova e é muito simples para dizer que é a algo verídico, mas as duas buscas trouxe documentos relacionados com a pesquisa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Documentos da consulta **recursos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos retornados pela consulta original:\n",
      "\n",
      "1 TRE-RJ nega registro de Cesar Maia para concorrer ao Senado\n",
      "2 Aécio anuncia subdivisão em programa de transferência\n",
      "3 Com recusa de Celso Amorim, Figueiredo deve ficar no Itamaraty \n",
      "4 A superfície e o subsolo das eleições\n",
      "5 STJ julga recurso do coronel Ustra\n",
      "\n",
      "Documentos retornados pela consulta expandida:\n",
      "\n",
      "1 PT impulsiona cerimônia de posse da Dilma nas redes sociais\n",
      "2 PSB-Rede apresenta diretrizes do programa de governo\n",
      "3 Veja lista completa de ministros anunciados por Dilma\n",
      "4 Planalto confirma Juca Ferreira no Ministério da Cultura\n",
      "5 Se essa rua fosse minha\n"
     ]
    }
   ],
   "source": [
    "documentos = list(procurarOR([word2]))[5:10]\n",
    "documentos_extendidos = list(procurarOR(ex_word2))[5:10]\n",
    "print(\"Documentos retornados pela consulta original:\\n\")\n",
    "for i,indice in enumerate(documentos):\n",
    "    print i+1,titulo[indice]\n",
    "print(\"\\nDocumentos retornados pela consulta expandida:\\n\")\n",
    "for i,indice in enumerate(documentos_extendidos):\n",
    "    print i+1,titulo[indice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já no caso da pesquisa por **recursos** a pesquisa expandida e a original também parecem ter trazido documentos com o mesmo nível de relevância e muito relacionado a recursos políticos e econômicos, mas lembrando que é uma análise bem subjetiva e simples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Documentos da consulta **corinthians**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos retornados pela consulta original:\n",
      "\n",
      "1 PSDB organiza maratona de eventos pró-Aécio em MG\n",
      "2 Ibope aponta empate técnico entre Jatene e Helder Barbalho no PA\n",
      "3 Mistura de estações  \n",
      "4 Alckmin nomeia “homem de confiança” de Russomanno (PRB) para a direção do Procon\n",
      "5 Eunicio Oliveira será relator do projeto de terrorismo no Senado e ganha vitrine para disputar governo do Ceará\n",
      "\n",
      "Documentos retornados pela consulta expandida:\n",
      "\n",
      "1 Menor prestígio e verba faz diplomatas buscarem opções a carreira no Itamaraty  \n",
      "2 Em carta, João Paulo diz que vai se entregar mas não vai renunciar\n",
      "3 Cúpula da política externa proíbe uso de Facebook para queixas  \n",
      "4 Dilma tenta reduzir poder de PT e PMDB\n",
      "5 Executiva de banco  diz na Justiça que PT 'exigiu' sua demissão  \n"
     ]
    }
   ],
   "source": [
    "documentos = list(procurarOR([word3]))[16:21]\n",
    "documentos_extendidos = list(procurarOR(ex_word3))[16:21]\n",
    "print(\"Documentos retornados pela consulta original:\\n\")\n",
    "for i,indice in enumerate(documentos):\n",
    "    print i+1,titulo[indice]\n",
    "print(\"\\nDocumentos retornados pela consulta expandida:\\n\")\n",
    "for i,indice in enumerate(documentos_extendidos):\n",
    "    print i+1,titulo[indice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As buscas por corinthians na consulta original, pelo menos pelo título não parecem ter muita relação. Já alguns títulos de textos da busca expandida parecem ter mais relação com a busca, mostrando que em alguns casos a busca expandida pode melhorar o número de documentos relevantes retornados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#A expansão de consultas é mais adequada para melhorar o recall ou o precision? Por que?\n",
    "\n",
    "Para responder essa questão vou checar o número de documentos retornados pelas duas consultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N° documentos retornado pela consulta dilma:4269\n",
      "N° documentos retornado pela consulta expandida ['dilma', u'rousseff', u'\\xe9', u'disse']:7396\n"
     ]
    }
   ],
   "source": [
    "print \"N° documentos retornado pela consulta \"+word1+\":\"+str(len(procurarOR([word1])))\n",
    "print \"N° documentos retornado pela consulta expandida \"+str(ex_word1)+\":\"+str(len(procurarOR(ex_word1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N° documentos retornado pela consulta recursos:1025\n",
      "N° documentos retornado pela consulta expandida ['recursos', u'p\\xfablicos', u'fundo', u'petrobr\\xe1s']:2520\n"
     ]
    }
   ],
   "source": [
    "print \"N° documentos retornado pela consulta \"+word2+\":\"+str(len(procurarOR([word2])))\n",
    "print \"N° documentos retornado pela consulta expandida \"+str(ex_word2)+\":\"+str(len(procurarOR(ex_word2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N° documentos retornado pela consulta corinthians:22\n",
      "N° documentos retornado pela consulta expandida ['corinthians', u'andr\\xe9s', u'2010', u'paulo']:3934\n"
     ]
    }
   ],
   "source": [
    "print \"N° documentos retornado pela consulta \"+word3+\":\"+str(len(procurarOR([word3])))\n",
    "print \"N° documentos retornado pela consulta expandida \"+str(ex_word3)+\":\"+str(len(procurarOR(ex_word3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que os 3 casos o número de documentos retornados pelas consultas expandidas é bem maior que o número retornado pela consulta só com a palavra original.Isso sempre vai acontecer já que a consulta expandida contém o termo da consulta original e é uma busca por OR, então **no mínimo a consulta expandida trará o mesmo número de documentos que a consulta original**, como podemos ver em geral ela trará mais documentos. Com base nisso, em relação ao **recall**(N° de documentos relevantes retornados dentre todos os relevantes), então podemos ver que o **recall da consulta expandida sempre será maior ou igual ao recall da consulta original**. No entando **sobre a precision não podemos afirmar nada com certeza**, pode ser um trade-off ao mesmo tempo que aumentasmo o recall, aumentando o número de documentos retornados, podemos está diminuindo, ou não, o precision da consulta. Não sabemos quantos dos novos documentos retornados são relevantes para a consulta. Como a consulta binária não faz um raking dos documentos, é difícil afirmar se os documentos são relevantes ou não, mas por eurísticas e testes já feitos anteriormente por pesquisadores da área, foi mostrado que na maioria dos casos a busca expandida melhora o retorno da consulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
