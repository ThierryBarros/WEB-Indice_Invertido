{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix and Vocabulary Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código feito pelos monitores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import math\n",
    "__author__ = \"Thierry Barros\"\n",
    "\n",
    "indice_invertido = {}\n",
    "dados_TF = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"../data/estadao_noticias_eleicao.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content = news.titulo + \" \" + news.subTitulo + \" \" + news.conteudo\n",
    "content = content.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def co_occurrence_matrix(corpus):\n",
    "    vocab = set(corpus)\n",
    "    vocab = list(vocab)\n",
    "    n = len(vocab)\n",
    "   \n",
    "    vocab_to_index = {word:i for i, word in enumerate(vocab)}\n",
    "    \n",
    "    bi_grams = list(bigrams(corpus))\n",
    "\n",
    "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
    "\n",
    "    I=list()\n",
    "    J=list()\n",
    "    V=list()\n",
    "    \n",
    "    for bigram in bigram_freq:\n",
    "        current = bigram[0][1]\n",
    "        previous = bigram[0][0]\n",
    "        count = bigram[1]\n",
    "\n",
    "        I.append(vocab_to_index[previous])\n",
    "        J.append(vocab_to_index[current])\n",
    "        V.append(count)\n",
    "        \n",
    "    co_occurrence_matrix = sparse.coo_matrix((V,(I,J)), shape=(n,n))\n",
    "\n",
    "    return co_occurrence_matrix, vocab_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens_lists = content.apply(lambda text: tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopword_ = stopwords.words('portuguese')\n",
    "filtered_tokens = tokens_lists.apply(lambda tokens: [token for token in tokens stopword_ = stopwords.words('portuguese')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming list of lists into one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = [token for tokens_list in filtered_tokens for token in tokens_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix, vocab = co_occurrence_matrix(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consult Bigram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consultable_matrix = matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def consult_frequency(w1, w2):\n",
    "    return(consultable_matrix[vocab[w1],vocab[w2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código do lab 1 para pesquisa OR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preencher( tupla ):\n",
    "    palavra, id_texto = tupla\n",
    "    if palavra.lower() not in dados_TF[id_texto]:\n",
    "        dados_TF[id_texto][palavra.lower()] = 0\n",
    "    dados_TF[id_texto][palavra.lower()] += 1\n",
    "    try:\n",
    "        indice_invertido [ palavra.lower() ].add(id_texto)\n",
    "    except KeyError:\n",
    "        indice_invertido[ palavra.lower() ] = set([ id_texto ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def extrair( texto , id_texto ):\n",
    "    for i in xrange( len(texto) ):\n",
    "        dados_TF[id_texto[i]]= {}\n",
    "        for palavra in nltk.word_tokenize( str(texto[i]).decode('utf-8') ):\n",
    "            preencher((palavra,id_texto[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Faça uma busca disjuntiva (OR) considerando a nova consulta.\n",
    "\n",
    "**Função de busca OR Binário.**\n",
    "Função de busca que retorna os documentos que possuem pelo menos uma das palavras da consulta. Função de labs anteriores é uma função de busca binária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def procurarOR(lista):\n",
    "    indices = indice_invertido[lista[0].lower()]\n",
    "    for palavra in lista:\n",
    "        indices = set(reduce( lambda x,y : list( x | y ), [ indice_invertido[palavra.lower()] , indices] ))\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Função main** que roda o programa e cria o indíce invertido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-944097910e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfile_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_csv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtexto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_csv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitulo\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_csv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconteudo\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_csv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubTitulo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mextrair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexto\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_csv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midNoticia\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-ddaa3b74dcec>\u001b[0m in \u001b[0;36mextrair\u001b[0;34m(texto, id_texto)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextrair\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtexto\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mid_texto\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexto\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdados_TF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_texto\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpalavra\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexto\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xrange' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_csv = pd.read_csv(\"../data/estadao_noticias_eleicao.csv\")\n",
    "    file_csv = file_csv.replace(np.nan, '', regex=True)\n",
    "    texto = file_csv.titulo + \" \" + file_csv.conteudo + \" \" + file_csv.subTitulo\n",
    "    extrair(texto,file_csv.idNoticia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código do Lab2 - Expansão de Consultas.\n",
    "\n",
    "#Escreva uma função que receba um certo termo de consulta e a matriz construída no passo 1 acima e retorne as top-3 palavras em ordem decrescente de frequencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função pega os tokens(todas as palavras do dicionário), faz um set para tirar as repetições, depois tranforma e lista denovo. Então eu crio uma lista(dic), contendo tuplas de (palavra, frequência da palavra com o termo). Após a criação dessa lista, eu ordeno ela pela frequência, e pego as três palavras com maior frequência e retorno elas. \n",
    "OBS: Crio essa lista de nome, frequencia, ultilizando a função auxiliar consult_frequency(word, i), criada pelos monitores da turma, então eu não preciso receber na função a matrix de co-ocorrência, porque essa função já usa a matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top3_similarity(word):\n",
    "    words = set(tokens)\n",
    "    words = list(words)\n",
    "    dic = []\n",
    "    for i in words:\n",
    "        try:\n",
    "            dic.append((i, consult_frequency(word, i)))\n",
    "        except KeyError:\n",
    "            return [\"Not Found: palavra '\"+word+\"' não encontrada\"]\n",
    "    dic.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    similar_words = []\n",
    "    for tupla in dic[:3]:\n",
    "       similar_words.append(tupla[0])\n",
    "    return similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Expanda a consulta original com os termos retornados no passo 2 acima.\n",
    "\n",
    "Essa função recebe o termo a ser procurado e retorna a lista expandida com os top3 palavras mais similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expand_consult(word):\n",
    "    words = []\n",
    "    words.append(word)\n",
    "    words += top3_similarity(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Escolha livremente três termos de consulta e responda o seguinte:\n",
    "\n",
    "**Os três termos escolhidos foram: Poucos, recursos, corinthians.**\n",
    "\n",
    "#Quais os termos retornados para a expansão de cada consulta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word1 = \"poucos\"\n",
    "word2 = \"recursos\"\n",
    "word3 = \"corinthians\"\n",
    "\n",
    "ex_word1 = top3_similarity(word1)\n",
    "\n",
    "ex_word2 = top3_similarity(word2)\n",
    "\n",
    "ex_word3 = top3_similarity(word3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Consulta **poucos**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Termos encontrados na expansão da pesquisa de \"+term1+\":\")\n",
    "for i, word in enumerate(ex_word1):\n",
    "    print i+1,word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Você acha que esses termos são de fato relacionados com a consulta original? Justifique.**\n",
    "\n",
    "Sim, pois são termos que em conjunto fazem sentido. Exemplo: poucos dias, poucos meses, poucos metros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Consulta **recursos**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Termos encontrados na expansão da pesquisa de \"+term2+\":\")\n",
    "for i, word in enumerate(ex_word2):\n",
    "    print i+1,word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Você acha que esses termos são de fato relacionados com a consulta original? Justifique.**\n",
    "\n",
    "Sim, mas acho que só duas das palavras fazem sentido, que são públicos e petrobrás. Recursos fundo não parece fazer muito sentido em conjunto, mas pode ser porque a frase não está completa, poderia ter outras palavras após essas que na frase fariam mais sentido. Já, recursos públicos e recursos petrobrás parece fazer sentido, deve possivelmente está relacionado ao interesse dos usuários em saber como estão sendo gastos os recursos do país."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Consulta **corinthians**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Termos encontrados na expansão da pesquisa de \"+term3+\":\")\n",
    "for i, word in enumerate(ex_word3):\n",
    "    print i+1,word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Você acha que esses termos são de fato relacionados com a consulta original? Justifique.**\n",
    "\n",
    "Sim, pois Andrés é o presidente do timão. 2010 deve ter sido a pesquisa em alta no ano da captação desses dados, procurando saber como o corinthians foi ou que jogos ele teria no ano de 2010. Paulo pode ser uma palavra ambígua, oque pode trazer problemas com falsos positivos caso seja uma palavra estatísticamente irrelevante, mas ela tanto pode representar o estado de São paulo, ou algum jogador chamado Paulo que fez sucesso no corinthians na época, confesso que não lembro de nenhum jogador com esse nome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare os documentos retornados para a consulta original com a consulta expandida. Quais resultados você acha que melhor capturam a necessidade de informação do usuário? Por que?**\n",
    "\n",
    "Para responder essa questão vou pegar **5 documentos** da consulta com o **termo original** e da consulta **expandida** e olhar manualmente quais documentos de quais pesquisas são **mais relevantes para a consulta original**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Documentos da consulta **poucos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(procurarOR([word1])[:5])\n",
    "print(procurarOR(ex_word1)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Documentos da consulta **recursos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(procurarOR([word2])[:5])\n",
    "print(procurarOR(ex_word2)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Documentos da consulta **corinthians**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(procurarOR([word3])[:5])\n",
    "print(procurarOR(ex_word3)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#A expansão de consultas é mais adequada para melhorar o recall ou o precision? Por que?\n",
    "\n",
    "Para responder essa questão vou checar o número de documentos retornados pelas duas consultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"N° documentos retornado pela consulta \"+word1+\":\"+len(procurarOR([word1]))\n",
    "print(\"N° documentos retornado pela consulta expandida \"+ex_word1+\":\"+len(procurarOR(ex_word1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"N° documentos retornado pela consulta \"+word1+\":\"+len(procurarOR([word2]))\n",
    "print(\"N° documentos retornado pela consulta expandida \"+ex_word1+\":\"+len(procurarOR(ex_word2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"N° documentos retornado pela consulta \"+word1+\":\"+len(procurarOR([word3]))\n",
    "print(\"N° documentos retornado pela consulta expandida \"+ex_word1+\":\"+len(procurarOR(ex_word3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que os 3 casos o número de documentos retornados pelas consultas expandidas é bem maior que o número retornado pela consulta só com a palavra original.Isso sempre vai acontecer já que a consulta expandida contém o termo da consulta original e é uma busca por OR, então **no mínimo a consulta expandida trará o mesmo número de documentos que a consulta original**, como podemos ver em geral ela trará mais documentos. Com base nisso, em relação ao **recall**(N° de documentos relevantes retornados dentre todos os relevantes), então podemos ver que o **recall da consulta expandida sempre será maior ou igual ao recall da consulta original**. No entando **sobre a precision não podemos afirmar nada com certeza**, pode ser um trade-off ao mesmo tempo que aumentasmo o recall, aumentando o número de documentos retornados, podemos está diminuindo, ou não, o precision da consulta. Não sabemos quantos dos novos documentos retornados são relevantes para a consulta. Como a consulta binária não faz um raking dos documentos, é difícil afirmar se os documentos são relevantes ou não, mas por eurísticas e testes já feitos anteriormente por pesquisadores da área, foi mostrado que na maioria dos casos a busca expandida melhora o retorno da consulta."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
